{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "import csv\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pages(main):\n",
    "    try:\n",
    "        soup = connect(main)\n",
    "        n_pages = [_.get_text(strip=True) for _ in soup.find('ul', {'class': 'pagination pagination__number'}).find_all('li')]\n",
    "        #max = soup.find_all(\"span\", class_=\"pagination__number\")\n",
    "        last_page = int(n_pages[-1])\n",
    "        pages = [main]\n",
    "        \n",
    "        for n in range(2,last_page+1):    \n",
    "            page_num = \"/?pag={}\".format(n)\n",
    "            pages.append(main + page_num)\n",
    "    except:\n",
    "        pages = [main]\n",
    "        \n",
    "    return pages\n",
    "\n",
    "def connect(web_addr):\n",
    "    resp = requests.get(web_addr)\n",
    "    return BeautifulSoup(resp.content, \"html.parser\")\n",
    "    \n",
    "\n",
    "def get_areas(website):\n",
    "    data = connect(website)\n",
    "    areas = []\n",
    "    for ultag in data.find_all('ul', {'class': 'breadcrumb-list breadcrumb-list_list breadcrumb-list__related'}):\n",
    "        for litag in ultag.find_all('li'):\n",
    "            for i in range(len(litag.text.split(','))):\n",
    "                areas.append(litag.text.split(',')[i])\n",
    "    areas = [x.strip() for x in areas]\n",
    "    urls = []\n",
    "    \n",
    "    for area in areas:\n",
    "        url = website + '/' + area.replace(' ','-').lower()\n",
    "        urls.append(url)\n",
    "    \n",
    "    return areas, urls\n",
    "\n",
    "def get_apartment_links(website):\n",
    "    data = connect(website)\n",
    "    links = []\n",
    "    for link in data.find_all('ul', {'class': 'annunci-list'}):\n",
    "        for litag in link.find_all('li'):\n",
    "            try:\n",
    "                #return litag.a.get('href')\n",
    "                links.append(litag.a.get('href'))\n",
    "            except:\n",
    "                continue\n",
    "    return links\n",
    "\n",
    "#def scrape_link(website):\n",
    "#    data = connect(website)\n",
    "#    nomi = []\n",
    "#    valori = []\n",
    "#    temp = []\n",
    "#    for link in (data.find_all('dd', {'class': 'im-features__value'})[1], data.find_all('dd', {'class': 'im-features__value'})[9], data.find_all('dd', {'class': 'im-features__value'})[12]):\n",
    "#        temp.append(link)\n",
    "#        try:\n",
    "#            temp = str(temp).replace('</dd>', '')\n",
    "#            temp = str(temp).replace('<dt', '</dd><dt')\n",
    "#            temp = BeautifulSoup(temp, \"html.parser\")\n",
    "#            for elem in temp.find_all('dd'):\n",
    "#                valori.append(elem.string.strip())\n",
    "#        except:\n",
    "#            #print('errore')\n",
    "#            pass\n",
    "#        temp = []\n",
    "#\n",
    "#    valori[-1] = (data.find_all('dd', {'class': 'im-features__value'})[0].find_all('span')[0].string)\n",
    "#\n",
    "#    for link in data.find_all('dt'):\n",
    "#        if link.string == None:\n",
    "#            pass\n",
    "#        else:\n",
    "#            nomi.append(link.string.strip())\n",
    "#\n",
    "#    while len(valori)<len(nomi):\n",
    "#        valori.append(0)\n",
    "#\n",
    "#    while len(nomi)<len(valori):\n",
    "#        nomi.append('Prestazione energetica del fabbricato')\n",
    "#\n",
    "#    count = 0\n",
    "#    nomi.append('Arredato S/N')\n",
    "#    nomi.remove('altre caratteristiche')\n",
    "#    for elem in data.find_all('dd', {'class': 'im-features__value'})[8].find_all('span'):\n",
    "#        if elem.string.strip() == \"Arredato\" or elem.string == \"Non arredato\" or elem.string == \"Parzialmente arredato\":\n",
    "#            valori.append(elem.string.strip())\n",
    "#            count = 1            \n",
    "#        else:\n",
    "#            continue\n",
    "#    if count == 0:\n",
    "#        valori.append('0')        \n",
    "#\n",
    "#    valori = remove_duplicates(valori)\n",
    "#    nomi = remove_duplicates(nomi)\n",
    "#    \n",
    "#    return nomi, valori\n",
    "\n",
    "def scrape_link(website):\n",
    "    data = connect(website)\n",
    "    info = data.find_all('dl', {'class': 'im-features__list'})\n",
    "    comp_info = pd.DataFrame()\n",
    "    cleaned_id_text = []\n",
    "    cleaned_id__attrb_text = []\n",
    "    for n in range(len(info)):\n",
    "        for i in info[n].find_all('dt'):\n",
    "            cleaned_id_text.append(i.text)\n",
    "        for i in info[n].find_all('dd'):\n",
    "            cleaned_id__attrb_text.append(i.text)\n",
    "\n",
    "    comp_info['Id'] = cleaned_id_text\n",
    "    comp_info['Attribute'] = cleaned_id__attrb_text\n",
    "    comp_info\n",
    "    feature = []\n",
    "    for item in comp_info['Attribute']:\n",
    "        try:\n",
    "            feature.append(clear_df(item))\n",
    "        except:\n",
    "            feature.append(ultra_clear_df(item))\n",
    "\n",
    "    comp_info['Attribute'] = feature\n",
    "    #comp_info.set_index('Id', drop=True, inplace=True)\n",
    "    #comp_info.index.name = None\n",
    "    #comp_info = comp_info.T.reset_index().drop(columns='index')\n",
    "    return comp_info['Id'].values, comp_info['Attribute'].values\n",
    "    \n",
    "\n",
    "def remove_duplicates(x):\n",
    "    return list(dict.fromkeys(x))\n",
    "\n",
    "\n",
    "def clear_df(the_list):\n",
    "    the_list = (the_list.split('\\n')[1].split('  '))\n",
    "    the_list = [value for value in the_list if value != ''][0]\n",
    "    return the_list\n",
    "\n",
    "def ultra_clear_df(the_list):\n",
    "    the_list = (the_list.split('\\n\\n')[1].split('  '))\n",
    "    the_list = [value for value in the_list if value != ''][0]\n",
    "    the_list = (the_list.split('\\n')[0])\n",
    "    return the_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Those are district's links \n",
      "\n",
      "['https://www.immobiliare.it/affitto-case/torino/aurora', 'https://www.immobiliare.it/affitto-case/torino/barriera-di-milano', 'https://www.immobiliare.it/affitto-case/torino/rebaudengo', 'https://www.immobiliare.it/affitto-case/torino/barriera-di-lanzo', 'https://www.immobiliare.it/affitto-case/torino/falchera', 'https://www.immobiliare.it/affitto-case/torino/barca', 'https://www.immobiliare.it/affitto-case/torino/bertolla', 'https://www.immobiliare.it/affitto-case/torino/borgo-san-paolo', 'https://www.immobiliare.it/affitto-case/torino/cenisia', 'https://www.immobiliare.it/affitto-case/torino/borgo-vittoria', 'https://www.immobiliare.it/affitto-case/torino/parco-dora', 'https://www.immobiliare.it/affitto-case/torino/campidoglio', 'https://www.immobiliare.it/affitto-case/torino/san-donato', 'https://www.immobiliare.it/affitto-case/torino/cit-turin', 'https://www.immobiliare.it/affitto-case/torino/cavoretto', 'https://www.immobiliare.it/affitto-case/torino/gran-madre', 'https://www.immobiliare.it/affitto-case/torino/centro', 'https://www.immobiliare.it/affitto-case/torino/colle-della-maddalena', 'https://www.immobiliare.it/affitto-case/torino/superga', 'https://www.immobiliare.it/affitto-case/torino/crocetta', 'https://www.immobiliare.it/affitto-case/torino/san-secondo', 'https://www.immobiliare.it/affitto-case/torino/le-vallette', 'https://www.immobiliare.it/affitto-case/torino/lucento', 'https://www.immobiliare.it/affitto-case/torino/madonna-di-campagna', 'https://www.immobiliare.it/affitto-case/torino/lingotto', 'https://www.immobiliare.it/affitto-case/torino/nizza-millefonti', 'https://www.immobiliare.it/affitto-case/torino/madonna-del-pilone', 'https://www.immobiliare.it/affitto-case/torino/sassi', 'https://www.immobiliare.it/affitto-case/torino/mirafiori-sud', 'https://www.immobiliare.it/affitto-case/torino/pozzo-strada', 'https://www.immobiliare.it/affitto-case/torino/parella', 'https://www.immobiliare.it/affitto-case/torino/regio-parco', 'https://www.immobiliare.it/affitto-case/torino/vanchiglia', 'https://www.immobiliare.it/affitto-case/torino/vanchiglietta', 'https://www.immobiliare.it/affitto-case/torino/san-salvario', 'https://www.immobiliare.it/affitto-case/torino/santa-rita', 'https://www.immobiliare.it/affitto-case/torino/mirafiori-nord']\n"
     ]
    }
   ],
   "source": [
    "## Link for city main website\n",
    "## get areas inside the city (districts)\n",
    "\n",
    "website = \"https://www.immobiliare.it/affitto-case/torino\"\n",
    "areas, districts = get_areas(website)\n",
    "print(\"Those are district's links \\n\")\n",
    "print(districts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape cycle initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1df08f8b1ed4ecb94d0fdf0905f5db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "indirizzo = []\n",
    "location = []\n",
    "\n",
    "for url in tqdm(districts):\n",
    "    pages = get_pages(url)\n",
    "    for page in pages:\n",
    "        add = get_apartment_links(page)\n",
    "        indirizzo.append(add)\n",
    "        for num in range(0,len(add)):\n",
    "            location.append(url.rsplit('/', 1)[-1])\n",
    "        \n",
    "announces_links = [item for valore in indirizzo for item in valore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numerosity of announces:\n",
      "\n",
      "3525\n"
     ]
    }
   ],
   "source": [
    "## Check that what you scraped has a meaning...and save it\n",
    "\n",
    "print(\"The numerosity of announces:\\n\")\n",
    "print(len(announces_links))\n",
    "with open('announces_list.csv', 'w') as myfile:\n",
    "    wr = csv.writer(myfile)\n",
    "    wr.writerow(announces_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proper dataset creation by scraping every announce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b007bb543e2540f7934ad8aa5a79d765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3525.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## DATAFRAME ORIZZONTALE__USARE\n",
    "\n",
    "df_scrape = pd.DataFrame()\n",
    "to_be_dropped = []\n",
    "counter = 0\n",
    "for link in tqdm(list(announces_links)):\n",
    "    counter=counter+1\n",
    "    try:\n",
    "        nomi, valori = scrape_link(link)\n",
    "        df_temporaneo = pd.DataFrame(columns=nomi)\n",
    "        df_temporaneo.loc[len(df_temporaneo), :] = valori[0:len(nomi)]\n",
    "        df_scrape = df_scrape.append(df_temporaneo, sort=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        to_be_dropped.append(counter)\n",
    "        print(to_be_dropped)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in to_be_dropped:\n",
    "pd.DataFrame(location).to_csv('location.csv', sep=';')\n",
    "pd.DataFrame(to_be_dropped).to_csv('to_be_dropped.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_dropped.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in to_be_dropped:\n",
    "    del location[index-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in to_be_dropped:\n",
    "    del announces_links[index-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3525, 24)\n"
     ]
    }
   ],
   "source": [
    "print(df_scrape.shape)\n",
    "df_scrape['zona'] = location\n",
    "df_scrape['links'] = announces_links\n",
    "df_scrape.columns = map(str.lower, df_scrape.columns)\n",
    "df_scrape.to_csv('dataset.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrape = pd.read_csv('dataset.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scrape = df_scrape[['contratto', 'zona', 'tipologia', 'superficie', 'locali', 'piano', 'tipo proprietà', 'prezzo', 'spese condominio', 'spese aggiuntive', 'anno di costruzione', 'stato', 'riscaldamento', 'climatizzazione', 'classe energetica', 'posti auto', 'links']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(df):\n",
    "    price = []\n",
    "    rooms = []\n",
    "    surface = []\n",
    "    bathrooms = []\n",
    "    floor = []\n",
    "    contract = []\n",
    "    tipo = []\n",
    "    condominio = []\n",
    "    heating = []\n",
    "    built_in = []\n",
    "    state = []\n",
    "    riscaldamento = []\n",
    "    cooling = []\n",
    "    energy_class = []\n",
    "    tipologia = []\n",
    "    pr_type = []\n",
    "    arredato = []\n",
    "    \n",
    "    for tipo in df['tipologia']:\n",
    "        try:\n",
    "            tipologia.append(tipo)\n",
    "        except:\n",
    "            tipologia.append(None)\n",
    "    \n",
    "    for superficie in df['superficie']:\n",
    "        try:\n",
    "            if \"m\" in superficie:\n",
    "                s = superficie.replace(\" m²\", \"\")\n",
    "                surface.append(s)\n",
    "        except:\n",
    "            surface.append(None)\n",
    "    \n",
    "    for locali in df['locali']:\n",
    "        try:\n",
    "            rooms.append(locali[0:1])\n",
    "        except:\n",
    "            rooms.append(None)\n",
    "    \n",
    "    for prezzo in df['prezzo']:\n",
    "        try:\n",
    "            price.append(prezzo.replace(\"Affitto \", \"\").replace(\"€ \", \"\").replace(\"/mese\", \"\").replace(\".\",\"\"))\n",
    "        except:\n",
    "            price.append(None)\n",
    "            \n",
    "    for contratto in df['contratto']:\n",
    "        try:\n",
    "            contract.append(contratto.replace(\"\\n \",\"\"))\n",
    "        except:\n",
    "            contract.append(None)\n",
    "    \n",
    "    for piano in df['piano']:\n",
    "        try:\n",
    "            floor.append(piano.split(' ')[0])\n",
    "        except:\n",
    "            floor.append(None)\n",
    "    \n",
    "    for tipologia in df['tipo proprietà']:\n",
    "        try:\n",
    "            pr_type.append(tipologia.split(',')[0])\n",
    "        except:\n",
    "            pr_type.append(None)\n",
    "            \n",
    "    for condo in df['spese condominio']:\n",
    "        try:\n",
    "            if \"mese\" in condo:\n",
    "                condominio.append(condo.replace(\"€ \",\"\").replace(\"/mese\",\"\"))\n",
    "            else:\n",
    "                condominio.append(None)\n",
    "        except:\n",
    "            condominio.append(None)\n",
    "        \n",
    "    for ii in df['spese aggiuntive']:\n",
    "        try:\n",
    "            if \"anno\" in ii:\n",
    "                mese = int(int(ii.replace(\"€ \",\"\").replace(\"/anno\",\"\").replace(\".\",\"\"))/12)\n",
    "                heating.append(mese)\n",
    "            else:\n",
    "                heating.append(None)\n",
    "        except:\n",
    "            heating.append(None)\n",
    "   \n",
    "    for anno_costruzione in df['anno di costruzione']:\n",
    "        try:\n",
    "            built_in.append(anno_costruzione)\n",
    "        except:\n",
    "            built_in.append(None)\n",
    "    \n",
    "    for stato in df['stato']:\n",
    "        try:\n",
    "            stat = stato.replace(\" \",\"\").lower()\n",
    "            state.append(stat)\n",
    "        except:\n",
    "            state.append(None)\n",
    "    \n",
    "    for tipo_riscaldamento in df['riscaldamento']:\n",
    "        try:\n",
    "            if 'Centralizzato' in tipo_riscaldamento:\n",
    "                riscaldamento.append('centralizzato')\n",
    "            elif 'Autonomo' in tipo_riscaldamento:\n",
    "                riscaldamento.append('autonomo')\n",
    "        except:\n",
    "            riscaldamento.append(None)\n",
    "    \n",
    "    for clima in df['climatizzazione']:\n",
    "        try:\n",
    "            cooling.append(clima.lower().split(',')[0])\n",
    "        except:\n",
    "            cooling.append('None')\n",
    "    \n",
    "    for classe in df['classe energetica']:\n",
    "        try:\n",
    "            energy_class.append(classe[0:2])#.replace(\"\\n \",\"\"))\n",
    "        except:\n",
    "            energy_class.append(None)\n",
    "            \n",
    "    #for SN in df['Arredato S/N']:\n",
    "    #    try:\n",
    "    #        arredato.append(SN)\n",
    "    #    except:\n",
    "    #        arredato.append(None)\n",
    "    #        \n",
    "    \n",
    "    final_df = pd.DataFrame(columns=['contratto', 'zona', 'tipologia', 'superficie', 'locali', 'piano', 'tipo proprietà', 'prezzo', 'spese condominio', 'spese aggiuntive', 'anno di costruzione', 'stato', 'riscaldamento', 'climatizzazione', 'certificazione energetica', 'posti auto'])#, 'Arredato S/N'])\n",
    "    final_df['contratto'] = contract\n",
    "    final_df['tipologia'] = tipologia\n",
    "    final_df['superficie'] = surface\n",
    "    final_df['locali'] = rooms\n",
    "    final_df['piano'] = floor\n",
    "    final_df['tipo proprietà'] = pr_type\n",
    "    final_df['prezzo'] = price\n",
    "    final_df['spese condominio'] = condominio\n",
    "    final_df['spese riscaldamento'] = heating\n",
    "    final_df['anno di costruzione'] = built_in\n",
    "    final_df['stato'] = state\n",
    "    final_df['riscaldamento'] = riscaldamento\n",
    "    final_df['climatizzatore'] = cooling\n",
    "    final_df['classe energetica'] = energy_class\n",
    "    final_df['zona'] = df['zona'].values\n",
    "    #inal_df['Arredato S/N'] = arredato\n",
    "    final_df['link annuncio'] = announces_links\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = cleanup(df_scrape)\n",
    "final.to_csv('dataset_da_allenamento.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
